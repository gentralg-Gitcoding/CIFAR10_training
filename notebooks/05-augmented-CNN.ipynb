{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca6ec449",
   "metadata": {},
   "source": [
    "# Optimized+augmented PyTorch RGB CNN\n",
    "\n",
    "In this notebook, we train the winning CNN architecture from the Optuna run in notebook 04 on the CIFAR-10 dataset with image augmentation for improved generalization.\n",
    "\n",
    "## Notebook set-up\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82a9a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "from pathlib import Path\n",
    "\n",
    "# Third party imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Package imports\n",
    "from cifar10_tools.pytorch.evaluation import evaluate_model\n",
    "from cifar10_tools.pytorch.plotting import (\n",
    "    plot_sample_images, plot_learning_curves, \n",
    "    plot_confusion_matrix, plot_class_probability_distributions,\n",
    "    plot_evaluation_curves\n",
    ")\n",
    "from cifar10_tools.pytorch.training import train_model\n",
    "\n",
    "# Suppress Optuna info messages\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(315)\n",
    "np.random.seed(315)\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bdf7bf",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccd52b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10000 # Smaller batch size for augmented training\n",
    "epochs = 100       # Extended training with augmentation\n",
    "print_every = 20   # Print training progress every n epochs\n",
    "\n",
    "# CIFAR-10 class names in class order\n",
    "class_names = [\n",
    "    'airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "    'dog', 'frog', 'horse', 'ship', 'truck'\n",
    "]\n",
    "\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4d3943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best hyperparameters from Optuna study\n",
    "storage_path = Path('../data/pytorch/cnn_optimization.db')\n",
    "storage_url = f'sqlite:///{storage_path}'\n",
    "\n",
    "study = optuna.load_study(\n",
    "    study_name='cnn_optimization',\n",
    "    storage=storage_url\n",
    ")\n",
    "\n",
    "best_params = study.best_trial.params\n",
    "\n",
    "print('Loaded best hyperparameters from Optuna study:')\n",
    "\n",
    "for key, value in best_params.items():\n",
    "    print(f'  {key}: {value}')\n",
    "\n",
    "print(f'\\nBest validation accuracy from optimization: {study.best_trial.value:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e96d80",
   "metadata": {},
   "source": [
    "## 1. Load and preprocess CIFAR-10 data with augmentation\n",
    "\n",
    "CIFAR-10 contains 32x32 color images (3 channels) across 10 classes. We use RGB images with data augmentation to improve model generalization.\n",
    "\n",
    "### 1.1. Define transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0360329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training transform with augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Validation/test transform (no augmentation)\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "print('Training augmentations:')\n",
    "print('  - Random horizontal flip (p=0.5)')\n",
    "print('  - Random rotation (±15°)')\n",
    "print('  - Random translation (±10%)')\n",
    "print('  - Color jitter (brightness, contrast, saturation)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486fc3b6",
   "metadata": {},
   "source": [
    "### 1.2. Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51cb285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure data directory exists\n",
    "data_dir = Path('../data/pytorch/cifar10')\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load full training dataset (will split into train/val later)\n",
    "train_dataset_full = datasets.CIFAR10(\n",
    "    root=data_dir,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "# Load validation set with eval transform (no augmentation)\n",
    "val_dataset_base = datasets.CIFAR10(\n",
    "    root=data_dir,\n",
    "    train=True,\n",
    "    download=False,\n",
    "    transform=eval_transform\n",
    ")\n",
    "\n",
    "# Load test dataset with eval transform\n",
    "test_dataset = datasets.CIFAR10(\n",
    "    root=data_dir,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=eval_transform\n",
    ")\n",
    "\n",
    "# Split into train/val (80/20)\n",
    "n_train = int(0.8 * len(train_dataset_full))\n",
    "n_val = len(train_dataset_full) - n_train\n",
    "\n",
    "# Create index-based subsets\n",
    "generator = torch.Generator().manual_seed(315)\n",
    "train_indices, val_indices = random_split(\n",
    "    range(len(train_dataset_full)), \n",
    "    [n_train, n_val],\n",
    "    generator=generator\n",
    ")\n",
    "\n",
    "# Create subset datasets\n",
    "train_dataset = torch.utils.data.Subset(train_dataset_full, train_indices.indices)\n",
    "val_dataset = torch.utils.data.Subset(val_dataset_base, val_indices.indices)\n",
    "\n",
    "print(f'Training samples: {len(train_dataset)} (with augmentation)')\n",
    "print(f'Validation samples: {len(val_dataset)} (no augmentation)')\n",
    "print(f'Test samples: {len(test_dataset)} (no augmentation)')\n",
    "print(f'Image shape: {train_dataset_full[0][0].shape}')\n",
    "print(f'Number of classes: {len(class_names)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be773646",
   "metadata": {},
   "source": [
    "### 1.3. Visualize sample images (with augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd44460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot first 10 images from the training dataset (augmented)\n",
    "fig, axes = plot_sample_images(train_dataset, class_names, nrows=2, ncols=5)\n",
    "fig.suptitle('Augmented Training Images', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b61d00",
   "metadata": {},
   "source": [
    "### 1.4. Create `DataLoader()` objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5532420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders (data stays on CPU, moved to GPU per-batch)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True  # Faster CPU->GPU transfer\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f'Training batches: {len(train_loader)}')\n",
    "print(f'Validation batches: {len(val_loader)}')\n",
    "print(f'Test batches: {len(test_loader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f079e8f7",
   "metadata": {},
   "source": [
    "## 2. Build optimized CNN using best hyperparameters\n",
    "\n",
    "We create a CNN using the best hyperparameters found during Optuna optimization, then train it with data augmentation.\n",
    "\n",
    "### 2.1. Define model builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25be199d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn(\n",
    "    n_conv_blocks: int,\n",
    "    initial_filters: int,\n",
    "    fc_units_1: int,\n",
    "    fc_units_2: int,\n",
    "    dropout_rate: float,\n",
    "    use_batch_norm: bool\n",
    ") -> nn.Sequential:\n",
    "    '''Create a CNN with configurable architecture for RGB images.\n",
    "    \n",
    "    Args:\n",
    "        n_conv_blocks: Number of convolutional blocks (1-4)\n",
    "        initial_filters: Number of filters in first conv layer (doubles each block)\n",
    "        fc_units_1: Number of units in first fully connected layer\n",
    "        fc_units_2: Number of units in second fully connected layer\n",
    "        dropout_rate: Dropout probability\n",
    "        use_batch_norm: Whether to use batch normalization\n",
    "    \n",
    "    Returns:\n",
    "        nn.Sequential model\n",
    "    '''\n",
    "\n",
    "    layers = []\n",
    "    in_channels = 3  # RGB input\n",
    "    current_size = 32  # Input image size\n",
    "    \n",
    "    for block_idx in range(n_conv_blocks):\n",
    "        out_channels = initial_filters * (2 ** block_idx)\n",
    "        \n",
    "        # First conv in block\n",
    "        layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "\n",
    "        if use_batch_norm:\n",
    "            layers.append(nn.BatchNorm2d(out_channels))\n",
    "\n",
    "        layers.append(nn.ReLU())\n",
    "        \n",
    "        # Second conv in block\n",
    "        layers.append(nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1))\n",
    "\n",
    "        if use_batch_norm:\n",
    "            layers.append(nn.BatchNorm2d(out_channels))\n",
    "\n",
    "        layers.append(nn.ReLU())\n",
    "        \n",
    "        # Pooling and dropout\n",
    "        layers.append(nn.MaxPool2d(2, 2))\n",
    "        layers.append(nn.Dropout(dropout_rate))\n",
    "        \n",
    "        in_channels = out_channels\n",
    "        current_size //= 2\n",
    "    \n",
    "    # Calculate flattened size\n",
    "    final_channels = initial_filters * (2 ** (n_conv_blocks - 1))\n",
    "    flattened_size = final_channels * current_size * current_size\n",
    "    \n",
    "    # Classifier (3 fully connected layers)\n",
    "    layers.append(nn.Flatten())\n",
    "    layers.append(nn.Linear(flattened_size, fc_units_1))\n",
    "    layers.append(nn.ReLU())\n",
    "    layers.append(nn.Dropout(dropout_rate))\n",
    "    layers.append(nn.Linear(fc_units_1, fc_units_2))\n",
    "    layers.append(nn.ReLU())\n",
    "    layers.append(nn.Dropout(dropout_rate))\n",
    "    layers.append(nn.Linear(fc_units_2, num_classes))\n",
    "    \n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1395899",
   "metadata": {},
   "source": [
    "### 2.2. Create model with best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6c953a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model with best hyperparameters from Optuna\n",
    "model = create_cnn(\n",
    "    n_conv_blocks=best_params['n_conv_blocks'],\n",
    "    initial_filters=best_params['initial_filters'],\n",
    "    fc_units_1=best_params['fc_units_1'],\n",
    "    fc_units_2=best_params['fc_units_2'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    use_batch_norm=best_params['use_batch_norm']\n",
    ").to(device)\n",
    "\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(model)\n",
    "print(f'\\nTotal parameters: {trainable_params:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0ea632",
   "metadata": {},
   "source": [
    "### 2.3. Define loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e730784b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Create optimizer with best hyperparameters\n",
    "if best_params['optimizer'] == 'Adam':\n",
    "    optimizer = optim.Adam(model.parameters(), lr=best_params['learning_rate'])\n",
    "\n",
    "elif best_params['optimizer'] == 'SGD':\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(), \n",
    "        lr=best_params['learning_rate'],\n",
    "        momentum=best_params.get('sgd_momentum', 0.9)\n",
    "    )\n",
    "\n",
    "else:  # RMSprop\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=best_params['learning_rate'])\n",
    "\n",
    "print(f\"Optimizer: {best_params['optimizer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d56fb2",
   "metadata": {},
   "source": [
    "### 2.4. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fa74e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "history = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    epochs=epochs,\n",
    "    print_every=print_every,\n",
    "    device=device  # Enable per-batch GPU transfer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7847e0ec",
   "metadata": {},
   "source": [
    "### 2.5. Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f29512",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plot_learning_curves(history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3b5830",
   "metadata": {},
   "source": [
    "## 3. Evaluate model on test set\n",
    "\n",
    "### 3.1. Calculate test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74efda05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom evaluation with per-batch GPU transfer\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        test_total += labels.size(0)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "test_accuracy = 100 * test_correct / test_total\n",
    "print(f'Test accuracy: {test_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be024146",
   "metadata": {},
   "source": [
    "### 3.2. Per-class accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f07fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate per-class accuracy\n",
    "class_correct = {name: 0 for name in class_names}\n",
    "class_total = {name: 0 for name in class_names}\n",
    "\n",
    "for pred, true in zip(predictions, true_labels):\n",
    "\n",
    "    class_name = class_names[true]\n",
    "    class_total[class_name] += 1\n",
    "\n",
    "    if pred == true:\n",
    "        class_correct[class_name] += 1\n",
    "\n",
    "print('Per-class accuracy:')\n",
    "print('-' * 30)\n",
    "\n",
    "for name in class_names:\n",
    "    acc = 100 * class_correct[name] / class_total[name]\n",
    "    print(f'{name:12s}: {acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce249a6",
   "metadata": {},
   "source": [
    "### 3.3. Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920a6ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_confusion_matrix(true_labels, predictions, class_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc7896b",
   "metadata": {},
   "source": [
    "### 3.4. Predicted class probability distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c1bf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted probabilities for all test samples\n",
    "model.eval()\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, _ in test_loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        outputs = model(images)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        all_probs.append(probs.cpu().numpy())\n",
    "\n",
    "all_probs = np.concatenate(all_probs, axis=0)\n",
    "\n",
    "# Plot probability distributions\n",
    "fig, axes = plot_class_probability_distributions(all_probs, class_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bdada5",
   "metadata": {},
   "source": [
    "### 3.5. Evaluation curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cb9b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plot_evaluation_curves(true_labels, all_probs, class_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca517ca",
   "metadata": {},
   "source": [
    "## 4. Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3935d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models directory if it doesn't exist\n",
    "models_dir = Path('../models/pytorch')\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save model state dict\n",
    "model_path = models_dir / 'augmented_cnn.pth'\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'test_accuracy': test_accuracy,\n",
    "    'history': history\n",
    "}, model_path)\n",
    "\n",
    "print(f'Model saved to: {model_path}')\n",
    "print(f'Test accuracy: {test_accuracy:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
